{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e04508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install faker\n",
    "#pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd471048",
   "metadata": {},
   "source": [
    "Project: Optimizing Name Matching Algorithms for Sanctions Screening\n",
    "Project Goal:\n",
    "Develop and optimize a name-matching algorithm for sanctions and politically exposed person (PEP) screening. The solution will focus on improving precision and recall, benchmarking its performance, and automating testing processes.\n",
    "\n",
    "Key Objectives:\n",
    "Algorithm Development:\n",
    "\n",
    "Implement a fuzzy matching algorithm using libraries such as FuzzyWuzzy, rapidfuzz, or Levenshtein.\n",
    "Optimize matching rules for efficiency and effectiveness, considering diverse naming conventions and common misspellings.\n",
    "Benchmark Testing:\n",
    "\n",
    "Create an internal benchmark dataset with synthetic customer names and a list of sanctions/PEPs.\n",
    "Evaluate algorithm performance using precision, recall, and F1-score metrics.\n",
    "Compare results with external benchmarking tools (e.g., World-Check).\n",
    "Automation:\n",
    "\n",
    "Develop an automated pipeline in Python to test the algorithm on both synthetic and real-world-like datasets.\n",
    "Deploy the solution in a simulated environment to monitor real-time performance.\n",
    "Rule Optimization:\n",
    "\n",
    "Explore configurations for balancing precision and recall.\n",
    "Provide insights on trade-offs by calculating missed true positives and false positives.\n",
    "Operational Tools:\n",
    "\n",
    "Build a dashboard (e.g., Streamlit) for compliance teams to visualize matching results and tune rules dynamically.\n",
    "Introduce LLM-assisted (Large Language Model) explanations to provide clarity on why matches occur, improving decision-making speed for compliance agents.\n",
    "Scalability:\n",
    "\n",
    "Extend the algorithm to handle additional screening scenarios, such as vessel names or aliases.\n",
    "Implement modular code for easy integration with other screening tools.\n",
    "Data Requirements:\n",
    "Synthetic Customer Data:\n",
    "\n",
    "Names with variations (e.g., spelling mistakes, alternative spellings).\n",
    "Demographics to simulate naming conventions across regions.\n",
    "Sanctioned Entities Data:\n",
    "\n",
    "Publicly available sanctions lists (e.g., OFAC, UN sanctions).\n",
    "Benchmarking Data:\n",
    "\n",
    "Historical screening cases (synthetic data with true positives and false positives).\n",
    "Technologies and Tools:\n",
    "Programming Languages: Python (core) and basic Java for code integration.\n",
    "Libraries:\n",
    "FuzzyWuzzy, Levenshtein, or rapidfuzz for fuzzy matching.\n",
    "scikit-learn for precision/recall evaluation.\n",
    "Data Visualization: Streamlit or Plotly for dashboards.\n",
    "Automation: Pytest or unittest for automated testing pipelines.\n",
    "Deployment: Docker or Flask for staging.\n",
    "Deliverables:\n",
    "Name-Matching Algorithm:\n",
    "\n",
    "Optimized for precision and recall.\n",
    "Configurable rules for custom scenarios.\n",
    "Benchmark Dataset:\n",
    "\n",
    "Comprehensive test set for algorithm evaluation.\n",
    "Automation Pipeline:\n",
    "\n",
    "Automated testing and performance reporting.\n",
    "Interactive Dashboard:\n",
    "\n",
    "For visualizing screening results and optimizing rules.\n",
    "Documentation:\n",
    "\n",
    "Detailed explanation of methods, trade-offs, and deployment instructions.\n",
    "Impact Alignment with Job Role:\n",
    "Ownership: Demonstrates ability to take ownership of testing and tuning strategies.\n",
    "Automation: Highlights capability to automate processes for efficiency.\n",
    "Cross-Functional Skills: Showcases communication of insights to technical and non-technical stakeholders through dashboards and reports.\n",
    "Scalability: Reflects aptitude for designing solutions that grow with the business's needs.\n",
    "This project would directly address many aspects of the job description while giving you hands-on experience with key concepts in name screening, algorithm optimization, and compliance operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619003de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Name Matching Algorithm/data/customers_data.csv',\n",
       " 'Name Matching Algorithm/data/sanctioned_data.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Set seed for reproducibility\n",
    "Faker.seed(42)\n",
    "\n",
    "# Generate customer names\n",
    "def generate_customer_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        name = fake.name()\n",
    "        nationality = fake.country()\n",
    "        birthdate = fake.date_of_birth(minimum_age=18, maximum_age=70)\n",
    "        data.append({\"Name\": name, \"Nationality\": nationality, \"Birthdate\": birthdate})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate sanctioned names\n",
    "def generate_sanctioned_data(num_records):\n",
    "    sanctioned_names = []\n",
    "    for _ in range(num_records):\n",
    "        name = fake.name()\n",
    "        # Introduce some variations (e.g., typos, alias, transliterations)\n",
    "        variations = [\n",
    "            name,\n",
    "            name.lower(),\n",
    "            ''.join(random.sample(name, len(name))),  # Scrambled name\n",
    "            name.replace(\"a\", \"@\"),  # Typo\n",
    "        ]\n",
    "        sanctioned_names.append({\"Sanctioned_Name\": random.choice(variations)})\n",
    "    return pd.DataFrame(sanctioned_names)\n",
    "\n",
    "# Generate datasets\n",
    "num_customers = 1000\n",
    "num_sanctioned = 200\n",
    "\n",
    "customers_df = generate_customer_data(num_customers)\n",
    "sanctioned_df = generate_sanctioned_data(num_sanctioned)\n",
    "\n",
    "# Save datasets to CSV\n",
    "customers_df.to_csv(\"Name Matching Algorithm/data/customers_data.csv\", index=False)\n",
    "sanctioned_df.to_csv(\"Name Matching Algorithm/data/sanctioned_data.csv\", index=False)\n",
    "\n",
    "# Paths to generated datasets\n",
    "customer_file_path = \"Name Matching Algorithm/data/customers_data.csv\"\n",
    "sanctioned_file_path = \"Name Matching Algorithm/data/sanctioned_data.csv\"\n",
    "\n",
    "customer_file_path, sanctioned_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91ac11",
   "metadata": {},
   "source": [
    "### Develop and Test a Name-Matching Algorithm\n",
    "We will use fuzzy matching algorithms to compare customer names against the sanctioned list.\n",
    "\n",
    "Steps:\n",
    "Implement the name matching logic using rapidfuzz (faster and more flexible than FuzzyWuzzy).\n",
    "Tune the matching threshold to balance precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0948c1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name Matching Algorithm/data/matched_customers.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "customers_df = pd.read_csv(\"Name Matching Algorithm/data/customers_data.csv\")\n",
    "sanctioned_df = pd.read_csv(\"Name Matching Algorithm/data/sanctioned_data.csv\")\n",
    "\n",
    "# Define a function for fuzzy matching\n",
    "def match_name(customer_name, sanctioned_list, threshold=90):\n",
    "    # Find the best match for a given name in the sanctioned list\n",
    "    match, score, index = process.extractOne(customer_name, sanctioned_list, scorer=fuzz.ratio)\n",
    "    if score >= threshold:\n",
    "        return match, score\n",
    "    return None, 0\n",
    "\n",
    "# Perform name matching\n",
    "sanctioned_list = sanctioned_df[\"Sanctioned_Name\"].tolist()\n",
    "customers_df[\"Matched_Name\"], customers_df[\"Match_Score\"] = zip(\n",
    "    *customers_df[\"Name\"].apply(lambda x: match_name(x, sanctioned_list))\n",
    ")\n",
    "\n",
    "# Filter matches above a threshold\n",
    "matched_customers = customers_df[customers_df[\"Match_Score\"] > 0]\n",
    "\n",
    "# Save results for review\n",
    "matched_customers.to_csv(\"Name Matching Algorithm/data/matched_customers.csv\", index=False)\n",
    "\"Name Matching Algorithm/data/matched_customers.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bdf32",
   "metadata": {},
   "source": [
    "### Evaluate Performance (Precision, Recall, F1-Score)\n",
    "We need to measure how well the algorithm performs using synthetic true positives and false positives.\n",
    "\n",
    "Steps:\n",
    "1. Generate labels for true positives and false positives in the dataset.\n",
    "2. Compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ec2609f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0, 0.6666666666666666)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Generate synthetic ground truth (for demo purposes)\n",
    "customers_df[\"True_Positive\"] = customers_df[\"Name\"].apply(\n",
    "    lambda x: 1 if x in sanctioned_list else 0\n",
    ")\n",
    "customers_df[\"Predicted_Positive\"] = customers_df[\"Match_Score\"].apply(\n",
    "    lambda x: 1 if x > 0 else 0\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "recall = recall_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "f1 = f1_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "\n",
    "precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09170544",
   "metadata": {},
   "source": [
    "### Automate the Testing Pipeline\n",
    "Create a function to rerun the above steps with different datasets and thresholds. This can later be expanded into a fully automated pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fb4aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matching(customers_df, sanctioned_df, threshold=80):\n",
    "    sanctioned_list = sanctioned_df[\"Sanctioned_Name\"].tolist()\n",
    "    customers_df[\"Matched_Name\"], customers_df[\"Match_Score\"] = zip(\n",
    "        *customers_df[\"Name\"].apply(lambda x: match_name(x, sanctioned_list, threshold))\n",
    "    )\n",
    "    customers_df[\"Predicted_Positive\"] = customers_df[\"Match_Score\"].apply(\n",
    "        lambda x: 1 if x > 0 else 0\n",
    "    )\n",
    "    precision = precision_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    recall = recall_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    f1 = f1_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46aff244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 14:32:39.203 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/toluwalaseokuwoga/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Load data\n",
    "matched_customers = pd.read_csv(\"Name Matching Algorithm/data/matched_customers.csv\")\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"Sanctions Screening Dashboard\")\n",
    "\n",
    "threshold = st.slider(\"Match Threshold\", 0, 100, 80)\n",
    "filtered_matches = matched_customers[matched_customers[\"Match_Score\"] >= threshold]\n",
    "\n",
    "st.dataframe(filtered_matches)\n",
    "st.write(f\"Total Matches Above Threshold: {len(filtered_matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed50ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b261f6d1",
   "metadata": {},
   "source": [
    "# different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c866848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Set seed for reproducibility\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate complex customer data\n",
    "def generate_customer_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        name = fake.name()\n",
    "        nationality = fake.country()\n",
    "        birthdate = fake.date_of_birth(minimum_age=18, maximum_age=70)\n",
    "        data.append({\"Name\": name, \"Nationality\": nationality, \"Birthdate\": birthdate})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate complex sanctioned names with variations\n",
    "def generate_sanctioned_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        name = fake.name()\n",
    "        variations = [\n",
    "            name,\n",
    "            name.lower(),\n",
    "            ''.join(random.sample(name, len(name))),  # Scrambled name\n",
    "            name.replace(\"a\", \"@\"),  # Typo\n",
    "            name + \" Jr.\",  # Alias\n",
    "        ]\n",
    "        data.append({\"Sanctioned_Name\": random.choice(variations), \"Sanctioned_Nationality\": fake.country()})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate datasets\n",
    "num_customers = 2000\n",
    "num_sanctioned = 500\n",
    "\n",
    "customers_df = generate_customer_data(num_customers)\n",
    "sanctioned_df = generate_sanctioned_data(num_sanctioned)\n",
    "\n",
    "# Save datasets for reference\n",
    "customers_df.to_csv(\"customers_data.csv\", index=False)\n",
    "sanctioned_df.to_csv(\"sanctioned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c9a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allison Hill</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1961-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patrick Gardner</td>\n",
       "      <td>Nauru</td>\n",
       "      <td>1976-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel Wagner</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>1983-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meredith Barnes</td>\n",
       "      <td>Kiribati</td>\n",
       "      <td>1985-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abigail Shaffer</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>1976-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name     Nationality   Birthdate\n",
       "0     Allison Hill  Czech Republic  1961-05-28\n",
       "1  Patrick Gardner           Nauru  1976-05-15\n",
       "2    Daniel Wagner        Anguilla  1983-10-03\n",
       "3  Meredith Barnes        Kiribati  1985-03-29\n",
       "4  Abigail Shaffer           Qatar  1976-05-28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ae7a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sanctioned_Name</th>\n",
       "      <th>Sanctioned_Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mckenzie Green</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evoatSrs teentnP</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cr@ig Mcm@hon</td>\n",
       "      <td>Liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Martin</td>\n",
       "      <td>Qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Hudson Jr.</td>\n",
       "      <td>Swaziland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sanctioned_Name Sanctioned_Nationality\n",
       "0     Mckenzie Green            Switzerland\n",
       "1   evoatSrs teentnP  Sao Tome and Principe\n",
       "2      Cr@ig Mcm@hon                Liberia\n",
       "3     Michael Martin                  Qatar\n",
       "4  Thomas Hudson Jr.              Swaziland"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanctioned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c5a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize names and remove noise for better matching\n",
    "def preprocess_name(name):\n",
    "    # Remove special characters and standardize case\n",
    "    return re.sub(r\"[^a-zA-Z\\s]\", \"\", name).lower().strip()\n",
    "\n",
    "# Preprocess names in both datasets\n",
    "customers_df[\"Preprocessed_Name\"] = customers_df[\"Name\"].apply(preprocess_name)\n",
    "sanctioned_df[\"Preprocessed_Sanctioned_Name\"] = sanctioned_df[\"Sanctioned_Name\"].apply(preprocess_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9c6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use fuzzy matching to find the best matches between customer names and sanctioned names\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Define the fuzzy matching function\n",
    "def match_name(customer_name, sanctioned_list, threshold=85):\n",
    "    match, score, _ = process.extractOne(customer_name, sanctioned_list, scorer=fuzz.ratio)\n",
    "    if score >= threshold:\n",
    "        return match, score\n",
    "    return None, 0\n",
    "\n",
    "# Perform name matching\n",
    "sanctioned_list = sanctioned_df[\"Preprocessed_Sanctioned_Name\"].tolist()\n",
    "customers_df[\"Matched_Name\"], customers_df[\"Match_Score\"] = zip(\n",
    "    *customers_df[\"Preprocessed_Name\"].apply(lambda x: match_name(x, sanctioned_list))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0675db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.18604651162790697, Recall: 1.0, F1-Score: 0.3137254901960785\n"
     ]
    }
   ],
   "source": [
    "#Introduce a synthetic ground truth and evaluate the algorithm’s performance\n",
    "# Simulate ground truth for demonstration purposes\n",
    "customers_df[\"True_Positive\"] = customers_df[\"Name\"].apply(\n",
    "    lambda x: 1 if preprocess_name(x) in sanctioned_list else 0\n",
    ")\n",
    "customers_df[\"Predicted_Positive\"] = customers_df[\"Match_Score\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "recall = recall_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "f1 = f1_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3185c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incorporate attributes like nationality to improve filtering\n",
    "def contextual_filter(row):\n",
    "    # Match based on name and additional attributes like nationality\n",
    "    if row[\"Matched_Name\"] and row[\"Nationality\"] == sanctioned_df.loc[\n",
    "        sanctioned_df[\"Preprocessed_Sanctioned_Name\"] == row[\"Matched_Name\"], \"Sanctioned_Nationality\"\n",
    "    ].values[0]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "customers_df[\"Contextual_Match\"] = customers_df.apply(contextual_filter, axis=1)\n",
    "customers_df[\"Predicted_Positive\"] = customers_df[\"Contextual_Match\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577ce104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Threshold  Precision  Recall        F1\n",
      "0         80   0.052980     1.0  0.100629\n",
      "1         85   0.186047     1.0  0.313725\n",
      "2         90   0.421053     1.0  0.592593\n",
      "3         95   0.666667     1.0  0.800000\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance at different thresholds to find the optimal balance\n",
    "thresholds = [80, 85, 90, 95]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    customers_df[\"Matched_Name\"], customers_df[\"Match_Score\"] = zip(\n",
    "        *customers_df[\"Preprocessed_Name\"].apply(lambda x: match_name(x, sanctioned_list, threshold))\n",
    "    )\n",
    "    customers_df[\"Predicted_Positive\"] = customers_df[\"Match_Score\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    precision = precision_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    recall = recall_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    f1 = f1_score(customers_df[\"True_Positive\"], customers_df[\"Predicted_Positive\"])\n",
    "    results.append({\"Threshold\": threshold, \"Precision\": precision, \"Recall\": recall, \"F1\": f1})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62350b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 16:40:55.559 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/toluwalaseokuwoga/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Create a Streamlit dashboard to visualize results interactively\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Sanctions Screening Dashboard\")\n",
    "\n",
    "threshold = st.slider(\"Match Threshold\", 0, 100, 85)\n",
    "filtered_matches = customers_df[customers_df[\"Match_Score\"] >= threshold]\n",
    "\n",
    "st.dataframe(filtered_matches[[\"Name\", \"Matched_Name\", \"Match_Score\"]])\n",
    "st.write(f\"Total Matches Above Threshold: {len(filtered_matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f32e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results for future tuning and comparison\n",
    "results_df.to_csv(\"performance_log.csv\", mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b79f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
